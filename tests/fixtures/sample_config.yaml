llama_server: "/opt/llama-server/llama-server"

defaults:
  threads: 6
  threads_batch: 8
  batch_size: 512

profiles:
  brain:
    name: "Brain (GLM-4.7-Flash)"
    model_path: "/models/brain/model.gguf"
    system_prompt: "/models/brain/system.txt"
    port: 8081
    ctx_size: 16384
    temperature: 0.7

  coder:
    name: "Coder (Qwen2.5-Coder-7B)"
    model_path: "/models/coder/model.gguf"
    system_prompt: "/models/coder/system.txt"
    port: 8082
    ctx_size: 32768
    temperature: 0.3

